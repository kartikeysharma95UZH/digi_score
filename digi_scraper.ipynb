{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the number of valid and Invalid links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Links Count: 132\n",
      "Invalid Links Count: 3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# url = \"https://esch.lu/\"\n",
    "url = \"https://beaufort.lu/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all <a> tags with href attribute\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "valid_links = []\n",
    "invalid_links = []\n",
    "\n",
    "for link in links:\n",
    "    href = link.get(\"href\")\n",
    "    if href:\n",
    "        href = href.strip()  # Remove leading and trailing white spaces\n",
    "        # Exclude \"#\" values, telephone numbers, and non-HTTP(S) links from invalid_links list\n",
    "        if href.startswith(\"http://\") or href.startswith(\"https://\"):\n",
    "            # Make a GET request to the link URL\n",
    "            try:\n",
    "                link_response = requests.get(href)\n",
    "                if link_response.status_code == 200:\n",
    "                    valid_links.append(href)\n",
    "                else:\n",
    "                    invalid_links.append(href)\n",
    "            except requests.exceptions.RequestException:\n",
    "                invalid_links.append(href)\n",
    "\n",
    "print(\"Valid Links Count:\", len(set(valid_links)))\n",
    "print(\"Invalid Links Count:\", len(invalid_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "print(\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# access the links to the buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Button Links:\n",
      "https://citylife.esch.lu/actualites/\n",
      "https://administration.esch.lu/actualite/\n",
      "https://citylife.esch.lu/agenda/\n",
      "#panel-traffic\n",
      "#panel-traffic\n",
      "#panel-traffic\n",
      "#panel-alerts\n",
      "https://formulaires.esch.lu/Annuaire/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://esch.lu/\"  # Replace with the URL of the website you want to scrape\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all elements with class=\"button\"\n",
    "button_elements = soup.find_all(class_=\"button\")\n",
    "\n",
    "button_links = []\n",
    "\n",
    "for button in button_elements:\n",
    "    href = button.get(\"href\")\n",
    "    if href:\n",
    "        button_links.append(href)\n",
    "\n",
    "print(\"Button Links:\")\n",
    "for link in button_links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image\n",
    "\n",
    "url = \"https://esch.lu/\"\n",
    "url = \"https://beaufort.lu/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "address_element = soup.find(\"div\", class_=\"address\")\n",
    "# digital_services_section = soup.find(\"div\", class_=\"article-image\")\n",
    "\n",
    "if address_element:\n",
    "    address = address_element.text.strip()\n",
    "    print(\"Address:\", address)\n",
    "else:\n",
    "    print(\"Address not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_hours: Heures d'ouverture: 8:00 Ã  17:00 (du lundi au vendredi)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image\n",
    "\n",
    "url = \"https://esch.lu/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "open_hours_element = soup.find(\"div\", class_=\"opening-hours\")\n",
    "# digital_services_section = soup.find(\"div\", class_=\"article-image\")\n",
    "\n",
    "if open_hours_element:\n",
    "    open_hours = open_hours_element.text.strip()\n",
    "    print(\"open_hours:\", open_hours)\n",
    "else:\n",
    "    print(\"open_hours not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Media Links:\n",
      "https://www.facebook.com/VilleEsch/\n",
      "https://www.instagram.com/villeesch/ \n",
      "https://esch.tv/\n",
      "https://www.facebook.com/VilleEsch/\n",
      "https://www.instagram.com/villeesch/ \n",
      "https://esch.tv/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image\n",
    "\n",
    "url = \"https://esch.lu/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all elements with social media links or icons\n",
    "# social_media_elements = soup.find_all(class_=\"sw-swp_whatsapp_icon\")\n",
    "social_media_elements = soup.find_all(class_=\"social-icons\")\n",
    "social_media_elements\n",
    "\n",
    "social_media_links = []\n",
    "\n",
    "for element in social_media_elements:\n",
    "    links = element.find_all(\"a\")\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href:\n",
    "            social_media_links.append(href)\n",
    "\n",
    "print(\"Social Media Links:\")\n",
    "for link in social_media_links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of all available classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Class Names:\n",
      "menu-item-6223\n",
      "social-icons\n",
      "menu-item-10382\n",
      "current-temperature\n",
      "footer-links\n",
      "panels\n",
      "post\n",
      "logo-esch-tv\n",
      "page-template-page-home-php\n",
      "permanence\n",
      "page-template\n",
      "icon-arrow-long-right\n",
      "menu-item-type-post_type\n",
      "clearfix\n",
      "menu-item-10162\n",
      "dots\n",
      "wrapper\n",
      "menu-item-10386\n",
      "menu-item-10385\n",
      "col-2\n",
      "phone\n",
      "menu-item-object-page\n",
      "small-title\n",
      "icon-arrow-long-left\n",
      "title\n",
      "hidden-phone\n",
      "footer\n",
      "menu-item-10160\n",
      "label\n",
      "link-citylife\n",
      "status-publish\n",
      "page-template-page-home\n",
      "menu-item-6222\n",
      "location-container\n",
      "article-image\n",
      "cats\n",
      "discover-places\n",
      "visible-desktop\n",
      "col-departments\n",
      "citylife\n",
      "image\n",
      "menu-item-10194\n",
      "col-address\n",
      "menu-item-10161\n",
      "yoast-schema-graph\n",
      "article-content\n",
      "bus\n",
      "suivez-nous\n",
      "menu-item-10383\n",
      "hidden-desktop\n",
      "event-wrapper\n",
      "flex\n",
      "header\n",
      "wrap\n",
      "menu-item-24142\n",
      "col\n",
      "logo\n",
      "cookie-notice-selection\n",
      "weather\n",
      "icon-instagram\n",
      "copyright\n",
      "icon-arrow-footer\n",
      "map\n",
      "news-wrapper\n",
      "hotel\n",
      "parking\n",
      "address\n",
      "dot-mid\n",
      "news-container\n",
      "events\n",
      "social\n",
      "cookie-notice-container\n",
      "menu-item-6220\n",
      "info-bar\n",
      "buttons\n",
      "landing\n",
      "icon-facebook\n",
      "plus\n",
      "menu-item-77\n",
      "source-org\n",
      "origin\n",
      "date\n",
      "bike\n",
      "link-admin\n",
      "format-standard\n",
      "page-id-2\n",
      "esch-landing-map-logo\n",
      "date-end\n",
      "weather-display\n",
      "dot\n",
      "chantiers\n",
      "footer-site-switcher\n",
      "menu-item-10444\n",
      "content\n",
      "bottom-menu-holder\n",
      "menu-item-6116\n",
      "menu-item\n",
      "is-hidden\n",
      "menu-item-78\n",
      "updated\n",
      "nav\n",
      "infos\n",
      "menu\n",
      "search-wrapper\n",
      "border\n",
      "visible-mobile\n",
      "post-meta\n",
      "required\n",
      "news\n",
      "day\n",
      "opening-hours\n",
      "align_right\n",
      "administration\n",
      "icon-search-admin\n",
      "event\n",
      "description\n",
      "menu-item-object-custom\n",
      "no-js\n",
      "menu-item-10442\n",
      "dot-first\n",
      "dot-last\n",
      "welcome\n",
      "location\n",
      "opening-hours-container\n",
      "menu-item-type-custom\n",
      "places\n",
      "value\n",
      "home\n",
      "type-post\n",
      "discover\n",
      "contact\n",
      "menu-item-6115\n",
      "menu-item-6265\n",
      "icon-broken-clouds\n",
      "page\n",
      "menu-item-6221\n",
      "mobility\n",
      "menu-item-6217\n",
      "menu-item-28\n",
      "button\n",
      "place\n",
      "panel\n",
      "transport\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://esch.lu/\"  # Replace with the URL of the website you want to scrape\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "class_names = set()\n",
    "\n",
    "# Find all elements with class attribute\n",
    "elements = soup.find_all(class_=True)\n",
    "\n",
    "# Extract class names from each element\n",
    "for element in elements:\n",
    "    class_names.update(element[\"class\"])\n",
    "\n",
    "print(\"Available Class Names:\")\n",
    "for class_name in class_names:\n",
    "    print(class_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website http://www.islalocalcouncil.com/ does not have multilingual functionality.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def has_multilingual_functionality(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Check for language switcher\n",
    "    language_switcher = soup.find(class_=\"language-switcher\")\n",
    "    if language_switcher:\n",
    "        print(\"1111111\")\n",
    "        return True\n",
    "\n",
    "    # Check URL structure for language identifiers\n",
    "    url_parts = url.split(\"/\")\n",
    "    if any(part for part in url_parts if len(part) == 2 and part.islower()):\n",
    "        print(\"222222\")\n",
    "        return True\n",
    "\n",
    "    # Check HTML lang attribute\n",
    "    html_tag = soup.find(\"html\")\n",
    "    if html_tag and html_tag.get(\"lang\"):\n",
    "        print(\"333333\")\n",
    "        return True\n",
    "\n",
    "    # Check for language-specific content\n",
    "    language_elements = soup.find_all(class_=\"language-content\")\n",
    "    if language_elements:\n",
    "        print(\"4444444\")\n",
    "        return True\n",
    "\n",
    "    # Check metadata or language tags\n",
    "    meta_tags = soup.find_all(\"meta\")\n",
    "    for meta_tag in meta_tags:\n",
    "        if \"lang\" in meta_tag.attrs or \"xml:lang\" in meta_tag.attrs:\n",
    "            print(\"5555555\")\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# Provide the URL of the website to check\n",
    "website_url = \"https://esch.lu/\"\n",
    "website_url = \"https://beaufort.lu/\"\n",
    "# website_url = 'https://www.nadur.gov.mt/'\n",
    "# website_url = 'https://www.deutschland.de/en'\n",
    "website_url = \"https://www.jonava.lt/\"\n",
    "website_url = \"http://www.islalocalcouncil.com/\"\n",
    "\n",
    "\n",
    "has_multilingual = has_multilingual_functionality(website_url)\n",
    "if has_multilingual:\n",
    "    print(f\"The website {website_url} has multilingual functionality.\")\n",
    "else:\n",
    "    print(f\"The website {website_url} does not have multilingual functionality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check Mobile compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile Friendliness: MOBILE_FRIENDLY\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def check_mobile_compatibility(url):\n",
    "    api_url = 'https://searchconsole.googleapis.com/v1/urlTestingTools/mobileFriendlyTest:run'\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    payload = {'url': url, 'requestScreenshot': True}\n",
    "\n",
    "    response = requests.post(f'{api_url}?key={api_key}', headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "#     print(data)\n",
    "    \n",
    "    # Check for errors in the response\n",
    "    if 'error' in data:\n",
    "        print('An error occurred:', data['error']['message'])\n",
    "        # Handle the error as desired\n",
    "    else:\n",
    "        # Check if mobileFriendliness key exists\n",
    "        if 'mobileFriendliness' in data:\n",
    "            mobile_friendliness = data['mobileFriendliness']\n",
    "            print('Mobile Friendliness:', mobile_friendliness)\n",
    "        else:\n",
    "            print('Mobile friendliness status not available.')\n",
    "        \n",
    "        \n",
    "# Provide the URL of the website to check\n",
    "website_url = 'https://esch.lu/'\n",
    "website_url = 'https://beaufort.lu/'\n",
    "# website_url = 'https://www.nadur.gov.mt/'\n",
    "# website_url = 'https://www.deutschland.de/en' #F\n",
    "# website_url = 'https://www.jonava.lt/'\n",
    "# website_url = 'http://www.islalocalcouncil.com/' #NF\n",
    "\n",
    "https://hamrunspartansfc.com/\n",
    "https://www.strassen.lu/  \n",
    "https://www.hercegnovi.me/sr/\n",
    "    \n",
    "\n",
    "check_mobile_compatibility(website_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website https://www.ets.org/gre.html has chatbot support.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def check_chatbot_support(website_url):\n",
    "    response = requests.get(website_url)\n",
    "    javascript_code = response.text\n",
    "\n",
    "    # Define keywords or patterns that indicate chatbot presence\n",
    "    chatbot_keywords = ['chatbot', 'livechat', 'virtual assistant']\n",
    "\n",
    "    for keyword in chatbot_keywords:\n",
    "        if re.search(keyword, javascript_code, re.IGNORECASE):\n",
    "            print(f\"The website {website_url} has chatbot support.\")\n",
    "            return\n",
    "\n",
    "    print(f\"The website {website_url} does not have chatbot support.\")\n",
    "\n",
    "# Example usage\n",
    "# website_url = 'https://www.icicibank.com/'\n",
    "website_url = 'https://esch.lu/'\n",
    "# website_url = 'https://beaufort.lu/'\n",
    "# website_url = 'https://www.icicibank.com/' #Yes\n",
    "# website_url = 'https://www.jonava.lt/'#no\n",
    "# website_url = 'http://www.islalocalcouncil.com/' #No\n",
    "website_url = 'https://www.ets.org/gre.html' #Yes\n",
    "\n",
    "check_chatbot_support(website_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact us form (Formulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website https://esch.lu/ has a contact form.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def check_contact_form(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Check if there is an element with the class 'contact'\n",
    "    contact_element = soup.find(class_='contact')\n",
    "    if contact_element:\n",
    "        # Check if there is an 'a' element within the contact element\n",
    "        link_element = contact_element.find('a')\n",
    "        if link_element and link_element.get('href'):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "website_url = 'https://esch.lu/'\n",
    "has_contact_form = check_contact_form(website_url)\n",
    "\n",
    "if has_contact_form:\n",
    "    print(f\"The website {website_url} has a contact form.\")\n",
    "else:\n",
    "    print(f\"The website {website_url} does not have a contact form.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalise / Payment Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "websites = ['https://esch.lu/']  # Replace with your list of 1000 websites\n",
    "payment_keywords = ['mastercard', 'visa', 'paypal']  # Add more keywords as needed\n",
    "\n",
    "for website in websites:\n",
    "    try:\n",
    "        # Send a GET request to the website\n",
    "        response = requests.get(website)\n",
    "        \n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Check for specific elements indicating online payment services\n",
    "        payment_elements = soup.find_all('div', class_='payment-logo')  # Example: Searching for payment logos\n",
    "        \n",
    "        # Check for payment keywords in the website content\n",
    "        website_text = soup.get_text().lower()  # Convert the website content to lowercase for case-insensitive matching\n",
    "        \n",
    "        # Check if any payment keywords are present in the website content as whole words\n",
    "        payment_keywords_present = any(re.search(r\"\\b\" + re.escape(keyword) + r\"\\b\", website_text) for keyword in payment_keywords)\n",
    "        \n",
    "        if len(payment_elements) > 0 or payment_keywords_present:\n",
    "            print(f\"{website} offers online payment services.\")\n",
    "        else:\n",
    "            print(f\"{website} does not offer online payment services.\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error accessing {website}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_media_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://esch.lu/wp-content/uploads/2023/06/Untitled-830-Ã-360-px_UNICEF.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image\n",
    "\n",
    "url = \"https://esch.lu/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "digital_services_section = soup.find(\"div\", class_=\"article-image\")\n",
    "digital_services_section = soup.find(\"div\", class_=\"article-image\")\n",
    "\n",
    "if digital_services_section:\n",
    "    # Extract the image URL from the style attribute\n",
    "    style_attribute = digital_services_section.get(\"style\")\n",
    "    image_url = style_attribute.split(\"url('\")[1].split(\"')\")[0]\n",
    "    # Display the image using the extracted URL\n",
    "    display(Image(url=image_url))\n",
    "else:\n",
    "    print(\"Digital services section not found on the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('ATAI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a5bd05f7305901977d1548a9a057ab7833b238d223787166fbe3e2dc5aa56c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
